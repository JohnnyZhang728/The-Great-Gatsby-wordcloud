import jieba
import wordcloud
from imageio import imread
import numpy as np

mask = imread("butterfly.png")                                               # 导入词云的背景图片
# 创建exclude删除词库
exclude = {"我们", "盖茨", "汤姆", "黛西", "一个", "他们", "那个", "已经", "这个", "但是", "自己", "没有", "时候", "知道",\
           "可是", "然后", "什么", "乔丹", "现在", "可以", "因为", "仿佛", "还有", "告诉", "一样", "觉得", "起来", "同时",\
           "看到", "好像", "因此", "感到", "就是", "一种", "以前", "不是", "威尔逊", "于是", "一定", "你们", "地方", "一点",\
           "非常", "那些", "后来", "开始", "这种", "或者", "突然", "这样", "地说", "一切", "看着", "看看", "的话", "最后",\
           "不能", "出来", "那么", "这里", "问道", "看见", "接着", "正在", "一面", "之后", "东西", "一会", "一起", "外面",\
           "离开", "一下", "几个", "一件", "认识", "大家", "以为", "也许", "如果", "过去", "这时", "一会儿", "一张", "有点",\
           "似的", "一条", "那里", "下来", "明白", "名字", "可能", "忽然", "记得", "整个", "事情", "一次", "下午", "屋子里",\
           "当时", "尼克", "等到", "表示"}
f = open("了不起的盖茨比.txt", "r", encoding="utf-8")                        # 打开文件，只读，统一编码
t = f.read()                                                                # 读文件内容
f.close()                                                                   # 关闭文件

ls = jieba.lcut(t)                                                          # 使用jieba分词，将分割后的单词存在列表ls
txt = " ".join(ls)                                                          # 将ls中的每个元素之间用空格隔开，变成字符串形式给txt

# 创建词云对象，赋参数
w = wordcloud.WordCloud(\
    width=1000, height=700,\
    background_color="white",\
    stopwords=exclude,\
    font_path="msyh.ttc", mask=np.array(mask))

w.generate(txt)                                                             # 生成词云
w.to_file("了不起的盖茨比(中文译本)词云.png")                                # 形成的词云输出在"了不起的盖茨比(中文译本)词云.png"文件